language,multiple,babel,mbxp,humaneval_x,so_2023_language_percent,so_2023_language_rank,so_tags,github_prs,github_pushes,github_issues,github_stars,stack_gb,codeparrot_gb,alphacode_gb,codegen_gb,polycoder_gb,subreddit_members,subreddit_url,anecdote_1_content,anecdote_1_author,anecdote_1_url,anecdote_2_content,anecdote_2_author,anecdote_2_url,anecdote_3_content,anecdote_3_author,anecdote_3_url
Erlang,N/A,N/A,N/A,N/A,0.99%,38,"9,621","70,890","249,209","49,786","127,120",0,0,0,0,0,9.5k,https://www.reddit.com/r/erlang,It seems like ChatGPT doesn't know that much Erlang.,u/Ranugad,https://www.reddit.com/r/erlang/comments/11kl57z/comment/jbbw94t,"I recently asked ChatGPT to translate some Erlang code into Elixir. Here’s an edited transcript, for your amusement and edification…",Rich_Morin,https://elixirforum.com/t/asking-chatgpt-to-translate-erlang-to-elixir/53548,I don’t think anything automated is going to work well. ChatGPT might be interesting but you’ll almost certainly have to fix it up quite a bit. https://learnxinyminutes.com/docs/erlang/ gives a quick rundown on erlang syntax/semantics and https://learnyousomeerlang.com/ is a good book on it,u/boy-griv,https://www.reddit.com/r/AskProgramming/comments/10tave8/comment/j78bvj5
Julia,11,13,N/A,N/A,1.15%,37,"12,402","39,305","166,898","51,276","52,326",3.09,0.29,0,0,0,23.9k,https://reddit.com/r/julia,"I usually start my own articles with ChatGPT but the truth is that right now, if you want to say something interesting in the Julia space, you mostly need to write it yourself since the volume of content about Julia out there isn’t enough for the outputs of ChatGPT to be very useful since our ecosystem is so small.",u/LoganKilpatrick1,https://www.reddit.com/r/Julia/comments/zzvkso/comment/j2i6knx/,"It wasn't trained on sufficient Julia code. As with any machine learning model, ChatGPT is only able to regurgitate what's been fed into it. Also, this behaviour happens with basically every other topic, too. LLMs work by trying to predict what the next word in a sentence would be based on the previous string of words. If a sentence is incomplete, it's going to add a next word. That word is going to be whichever has the highest confidence score, regardless of low that score may actually be. This results in it just making shit up, but often shit that sounds plausible. We've seen CGPT invent academic articles, books, and even entire people because it makes sense to in the sentence it's generating.`",u/Kichae,https://www.reddit.com/r/Julia/comments/112wlle/comment/j8mpgx5/,"I suspect the current language model behind ChatGPT was fed with a lot of code examples from Stack Exchange, but the Julia community mainly uses Discourse instead, which probably wasn't in the training set: https://discourse.julialang.org/",u/Paravalis,https://www.reddit.com/r/Julia/comments/112wlle/comment/j8qzc0j/